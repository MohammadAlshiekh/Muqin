{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image gen func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as DALLE_20240205_180836.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('DALLE_20240205_180836.png',\n",
       " 'Subject: a serene landscape with a sunset. Style: impressionist painting.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import openai\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_image(prompt):\n",
    "    \"\"\"\n",
    "    Generates a single image based on a given prompt using DALL-E and saves it as a file.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The prompt to generate an image for.\n",
    "\n",
    "    Requires:\n",
    "    - openai (package): For making API requests to DALL-E.\n",
    "    - PIL (package): For image processing.\n",
    "\n",
    "    Note:\n",
    "    Ensure the OpenAI package is updated to version 1.2.3 or higher.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verify OpenAI package version\n",
    "    required_version = \"1.2.3\"\n",
    "    current_version = openai.__version__\n",
    "    if tuple(map(int, current_version.split(\".\"))) < tuple(map(int, required_version.split(\".\"))):\n",
    "        raise ValueError(f\"OpenAI version {current_version} is less than the required version {required_version}.\")\n",
    "\n",
    "    # Configuration for the image request\n",
    "    image_params = {\n",
    "        \"model\": \"dall-e-2\",\n",
    "        \"n\": 1,\n",
    "        \"size\": \"1024x1024\",\n",
    "        \"prompt\": prompt,\n",
    "    }\n",
    "\n",
    "    # Initialize OpenAI client using environment variable for API key\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    # Make the request to generate the image\n",
    "    try:\n",
    "        images_response = client.images.generate(**image_params)\n",
    "    except openai.error.OpenAIError as e:\n",
    "        raise Exception(f\"Failed to generate image: {e}\")\n",
    "\n",
    "    # Extract image URL\n",
    "    image_url = images_response.data[0].url\n",
    "\n",
    "    # Download and save the image\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        timestamp = datetime.utcfromtimestamp(images_response.created).strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"DALLE_{timestamp}.png\"\n",
    "        image.save(filename)\n",
    "        print(f\"Image saved as {filename}\")\n",
    "    else:\n",
    "        raise Exception(\"Failed to download the image.\")\n",
    "\n",
    "    return filename, prompt\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Subject: a serene landscape with a sunset. Style: impressionist painting.\"\n",
    "generate_image(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt eval func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: False, Reason: The prompt contains offensive language and would not be appropriate to be fed to DALL-E.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "def evaluate_prompt(prompt):\n",
    "    \"\"\"\n",
    "    Evaluates a prompt to determine if it makes sense for DALL-E visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The text prompt to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing a boolean evaluation result and a string reason.\n",
    "    \"\"\"\n",
    "    client = OpenAI()  # Assumes OpenAI API key is configured in the environment.\n",
    "\n",
    "    system_prompt = ''' Always return True, unless: prompt would not make sense if fed to DALL E'''\n",
    "\n",
    "    example_json_true = {\n",
    "        \"evaluation\": True,\n",
    "        \"reason\": \"The prompt could be visualizable using DALL E.\"\n",
    "    }\n",
    "\n",
    "    example_json_false = {\n",
    "        \"evaluation\": False,\n",
    "        \"reason\": \"The prompt cannot be visualizable using DALL E.\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Provide output in valid JSON. The data schema should be like this: \" + json.dumps(example_json_true) + \" or \" + json.dumps(example_json_false) +\n",
    "                 \" In the reason, you do not have to follow the exact same reason strings as the examples.\" +\n",
    "                 \" The criteria for making evaluation False or True is the following: \" + system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        finish_reason = chat_completion.choices[0].finish_reason\n",
    "\n",
    "        if finish_reason == \"stop\":\n",
    "            data = chat_completion.choices[0].message.content\n",
    "\n",
    "            evaluation = json.loads(data)\n",
    "            if evaluation[\"evaluation\"] == True:\n",
    "                return True, evaluation[\"reason\"]\n",
    "            else:\n",
    "                return False, evaluation[\"reason\"]\n",
    "        else:\n",
    "            return False, \"Error! Provide more tokens please.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the API call.\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False, \"An unexpected error occurred.\"\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Fuck\"\n",
    "result, reason = evaluate_prompt(prompt)\n",
    "print(f\"Evaluation: {result}, Reason: {reason}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newstart3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
